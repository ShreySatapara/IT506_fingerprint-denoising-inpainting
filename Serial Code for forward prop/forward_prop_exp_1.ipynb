{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cWzN7TEKNEzN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6RN5NOLx1nnU"
   },
   "outputs": [],
   "source": [
    "def make_ndarray(shape,value):\n",
    "    ndarray = []\n",
    "    try:\n",
    "        rows = shape[0]\n",
    "        cols = shape[1]\n",
    "        chan = shape[2]\n",
    "        for c in range(chan):\n",
    "            ndarray.append([])\n",
    "            for r in range(rows):\n",
    "                ndarray[c].append([])\n",
    "                for col in range(cols):\n",
    "                    ndarray[c][r].append(value)\n",
    "    except:\n",
    "        rows = shape[0]\n",
    "        cols = shape[1]\n",
    "        for r in range(rows):\n",
    "            ndarray.append([])\n",
    "            for col in range(cols):\n",
    "                ndarray[r].append(value)\n",
    "\n",
    "    return np.array(ndarray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "toC-g9jr1pLE"
   },
   "outputs": [],
   "source": [
    "def np_sum(array):\n",
    "    sum=0\n",
    "    try:\n",
    "        rows = array.shape[0]\n",
    "        cols = array.shape[1]\n",
    "        chan = array.shape[2]\n",
    "        for c in range(chan):\n",
    "            for r in range(rows):\n",
    "                for col in range(cols):\n",
    "                    sum+=array[c][r][col]\n",
    "    except:\n",
    "        rows = array.shape[0]\n",
    "        cols = array.shape[1]\n",
    "        for r in range(rows):\n",
    "            for col in range(cols):\n",
    "                sum+=array[r][col]        \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "73Fwnft-1pJa"
   },
   "outputs": [],
   "source": [
    "def np_multiply(array_1,array_2):\n",
    "    mul_array = make_ndarray(array_1.shape,1.)\n",
    "    try:\n",
    "        rows = mul_array.shape[0]\n",
    "        cols = mul_array.shape[1]\n",
    "        chan = mul_array.shape[2]\n",
    "        for c in range(chan):\n",
    "            for r in range(rows):\n",
    "                for col in range(cols):\n",
    "                    mul_array[c][r][col] = array_1[c][r][col]*array_2[c][r][col]\n",
    "    except:\n",
    "        rows = mul_array.shape[0]\n",
    "        cols = mul_array.shape[1]\n",
    "        for r in range(rows):\n",
    "            for col in range(cols):\n",
    "                mul_array[r][col] = array_1[r][col]*array_2[r][col]\n",
    "\n",
    "    return np.array(mul_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ypgC5dZA1pHo"
   },
   "outputs": [],
   "source": [
    "def sum_of_arrays(array_1,array_2):\n",
    "    summed_array = make_ndarray(array_1.shape,0.)\n",
    "    try:\n",
    "        rows = summed_array.shape[0]\n",
    "        cols = summed_array.shape[1]\n",
    "        chan = summed_array.shape[2]\n",
    "        for c in range(chan):\n",
    "            for r in range(rows):\n",
    "                for col in range(cols):\n",
    "                    summed_array[c][r][col] = array_1[c][r][col]+array_2[c][r][col]\n",
    "    except:\n",
    "        rows = summed_array.shape[0]\n",
    "        cols = summed_array.shape[1]\n",
    "        for r in range(rows):\n",
    "            for col in range(cols):\n",
    "                summed_array[r][col] = array_1[r][col]+array_2[r][col]\n",
    "\n",
    "    return np.array(summed_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WIOE_ns11YMA"
   },
   "outputs": [],
   "source": [
    "def relu_exp(a):\n",
    "    for dim1 in range(a.shape[0]):\n",
    "        for dim2 in range(a.shape[1]):\n",
    "            for dim3 in range(a.shape[2]):\n",
    "                for dim4 in range(a.shape[3]):\n",
    "                    if(a[dim1][dim2][dim3][dim4]<0):\n",
    "                        a[dim1][dim2][dim3][dim4] = 0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4VqeQY7YlRj",
    "outputId": "31bfb331-9559-4650-af6f-ee165f0af3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 288, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 400, 288, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = np.resize(cv2.imread('2.jpg')/255.,(400,288,3))\n",
    "print(img.shape)\n",
    "img = np.resize(img,(1,400,288,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bn3IAgRkNJmk"
   },
   "outputs": [],
   "source": [
    "from math import floor,ceil\n",
    "def zero_pad_same(m,X,strides,n_c,filter_size):\n",
    "  p_row = ceil(((X.shape[1] - 1) * strides[0] + filter_size[0] - X.shape[1])/2)\n",
    "  p_col = ceil(((X.shape[2] - 1) * strides[1] + filter_size[1] - X.shape[2])/2)\n",
    "  #print(p_row,p_col)\n",
    "  row_num = X.shape[1] + 2 * p_row\n",
    "  col_num = X.shape[2] + 2 * p_col\n",
    "  X_padded = np.zeros(shape=(m,row_num, col_num,n_c))\n",
    "  X_padded[0:m,p_row:p_row+X.shape[1], p_col:p_col+X.shape[2],0:n_c] = X\n",
    "  return X_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dDmj2h-lNQMi"
   },
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    # Element-wise product between a_slice and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev,W)\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + b.astype(float)\n",
    "    ### END CODE HERE ###\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pBBrSXu3NWnD"
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b,strides,filter_size):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros([m, n_H_prev, n_W_prev, n_C])\n",
    "    #print(Z.shape)\n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad_same(m, A_prev, strides, n_C_prev,filter_size)\n",
    "    #print(A_prev_pad.shape)\n",
    "\n",
    "    for i in range(m):                               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i,:,:,:]                              # Select ith training example's padded activation\n",
    "        for h in range(n_H_prev):                           # loop over vertical axis of the output volume\n",
    "            for w in range(n_W_prev):                       # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h*strides[0]\n",
    "                    vert_end = h*strides[0] + f\n",
    "                    horiz_start = w*strides[1] \n",
    "                    horiz_end = w*strides[1] + f\n",
    "                    \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    \n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[:,:,:,c])\n",
    "                                        \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H_prev, n_W_prev, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, strides, filter_size)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XmFcw1BhgpsC"
   },
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    #print(n_H,n_W,n_C)\n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = h*stride +f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = w*stride + f\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end,c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n",
    "                    \"\"\"max_elem = 0\n",
    "                    (_,dim1,dim2,_) = a_prev_slice.shape\n",
    "                    for d1 in range(dim1):\n",
    "                      for d2 in range(dim2):\n",
    "                        if(a_prev_slice[d1][d2]>max_elem):\n",
    "                          max_elem = a_prev_slice[d1][d2] \"\"\"\n",
    "                    A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NJZXft2kiPNO"
   },
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "def Conv2DTranspose(X, W, padding=\"valid\", strides=(1, 1)):\n",
    "    # Define output shape before padding\n",
    "    row_num = (X.shape[0] - 1) * strides[0] + W.shape[0]\n",
    "    col_num = (X.shape[1] - 1) * strides[1] + W.shape[1]\n",
    "    output = np.zeros([row_num, col_num])\n",
    "    # Calculate the output\n",
    "    for i in range(0, X.shape[0]):\n",
    "        i_prime = i * strides[0] # Index in output\n",
    "        for j in range(0, X.shape[1]):\n",
    "            j_prime = j * strides[1]\n",
    "            # Insert values\n",
    "            for k_row in range(W.shape[0]):\n",
    "                for k_col in range(W.shape[1]):\n",
    "                    output[i_prime+k_row, j_prime+k_col] += W[k_row, k_col] * X[i, j]\n",
    "    # Define length of padding\n",
    "    if padding == \"same\":\n",
    "        # returns the output with the shape of (input shape)*(stride)\n",
    "        p_left = floor((W.shape[0] - strides[0])/2)\n",
    "        p_right = W.shape[0] - strides[0] - p_left\n",
    "        p_top = floor((W.shape[1] - strides[1])/2)\n",
    "        p_bottom = W.shape[1] - strides[1] - p_left\n",
    "    elif padding == \"valid\":\n",
    "        # returns the output without any padding\n",
    "        p_left = 0\n",
    "        p_right = 0\n",
    "        p_top = 0\n",
    "        p_bottom = 0\n",
    "    # Add padding\n",
    "    output_padded = output[p_left:output.shape[0]-p_right, p_top:output.shape[0]-p_bottom]\n",
    "    return(np.array(output_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iNY6PKn4iyRv"
   },
   "outputs": [],
   "source": [
    "def Conv2DTranspose_layer(X, W, padding=\"same\", strides=(1,1)):\n",
    "    output = []\n",
    "    (m,height,width,n_c_prev) = X.shape\n",
    "    (f,f,n_c_prev,filters) = W.shape\n",
    "    for i in range(m):\n",
    "        final_output = []\n",
    "        for f in range(filters):\n",
    "            base_array = np.zeros((height*strides[0],width*strides[0]))  #initializing with zero\n",
    "            final_output.append([])\n",
    "            for c in range(n_c_prev):\n",
    "                one_channel_output = Conv2DTranspose(X[i,:,:,c],W[:,:,c,f],padding='same',strides=(2,2)) \n",
    "                #print(np.array(one_channel_output).shape)\n",
    "                one_kernel_output = sum_of_arrays(base_array,one_channel_output)\n",
    "                #print(np.array(one_kernel_output).shape)\n",
    "                base_array = one_kernel_output\n",
    "            final_output[-1] = one_kernel_output\n",
    "        output.append(final_output)\n",
    "    output = np.array(output)\n",
    "    return np.moveaxis(output,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tf8yndmsDJ1g"
   },
   "outputs": [],
   "source": [
    "def concat(X,X_prev):\n",
    "  (m,height,width,c) = X.shape\n",
    "  output = []\n",
    "  for i in range(m):\n",
    "    height_list = []\n",
    "    for h in range(height):\n",
    "      width_list = []\n",
    "      for w in range(width):\n",
    "        X1 = list(X[i][h][w])\n",
    "        X2 = list(X_prev[i][h][w])\n",
    "        X1.extend(X2)\n",
    "        width_list.append(X1)\n",
    "      height_list.append(width_list)\n",
    "    output.append(height_list)\n",
    "  return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ii3ZuJ1H2Nhc",
    "outputId": "ea81ae79-303b-4d97-9da5-9dc21a9347c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 288, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 400, 288, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = np.resize(cv2.imread('2.jpg')/255.,(400,288,3))\n",
    "print(img.shape)\n",
    "img = np.resize(img,(1,400,288,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for weight initilization: \t0.14403247833251953\n"
     ]
    }
   ],
   "source": [
    "#weight initilization of every layer\n",
    "init_start = time.time()\n",
    "W_11 = np.random.randn(3,3,3,32)\n",
    "b_11 = np.random.randn(1,1,1,32)\n",
    "W_12 = np.random.randn(3,3,32,32)\n",
    "b_12 = np.random.randn(1,1,1,32)\n",
    "W_21 = np.random.randn(3,3,32,64)\n",
    "b_21 = np.random.randn(1,1,1,64)\n",
    "W_22 = np.random.randn(3,3,64,64)\n",
    "b_22 = np.random.randn(1,1,1,64)\n",
    "W_31 = np.random.randn(3,3,64,128)\n",
    "b_31 = np.random.randn(1,1,1,128)   \n",
    "W_32 = np.random.randn(3,3,128,128)\n",
    "b_32 = np.random.randn(1,1,1,128)\n",
    "W_41 = np.random.randn(3,3,128,256)\n",
    "b_41 = np.random.randn(1,1,1,256)\n",
    "W_42 = np.random.randn(3,3,256,256)\n",
    "b_42 = np.random.randn(1,1,1,256)\n",
    "W_51 = np.random.randn(3,3,256,512)\n",
    "b_51 = np.random.randn(1,1,1,512)\n",
    "W_52 = np.random.randn(3,3,512,512)\n",
    "b_52 = np.random.randn(1,1,1,512)\n",
    "W_61 = np.random.randn(2,2,512,256)\n",
    "b_61 = np.random.randn(1,1,1,256)\n",
    "W_62 = np.random.randn(3,3,512,256)\n",
    "b_62 = np.random.randn(1,1,1,256)\n",
    "W_63 = np.random.randn(3,3,256,256)\n",
    "b_63 = np.random.randn(1,1,1,256)\n",
    "W_71 = np.random.randn(2,2,256,128)\n",
    "b_71 = np.random.randn(1,1,1,128)\n",
    "W_72 = np.random.randn(3,3,256,128)\n",
    "b_72 = np.random.randn(1,1,1,128)\n",
    "W_73 = np.random.randn(3,3,128,128)\n",
    "b_73 = np.random.randn(1,1,1,128)\n",
    "W_81 = np.random.randn(2,2,128,64)\n",
    "b_81 = np.random.randn(1,1,1,64)\n",
    "W_82 = np.random.randn(3,3,128,64)\n",
    "b_82 = np.random.randn(1,1,1,64)\n",
    "W_83 = np.random.randn(3,3,64,64)\n",
    "b_83 = np.random.randn(1,1,1,64)\n",
    "W_91 = np.random.randn(2,2,64,32)\n",
    "b_91 = np.random.randn(1,1,1,32)\n",
    "W_92 = np.random.randn(3,3,64,32)\n",
    "b_92 = np.random.randn(1,1,1,32)\n",
    "W_93 = np.random.randn(3,3,32,32)\n",
    "b_93 = np.random.randn(1,1,1,32)\n",
    "W_out = np.random.randn(1,1,32,1)\n",
    "b_out = np.random.randn(1,1,1,1)\n",
    "init_end = time.time()\n",
    "print('time for weight initilization: ',end='\\t')\n",
    "print(init_end - init_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image count</th>\n",
       "      <th>executing block</th>\n",
       "      <th>execution time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>weight init</td>\n",
       "      <td>0.147924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image count executing block  execution time\n",
       "0           1     weight init        0.147924"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "time_data = pd.DataFrame(columns=['image count','executing block','execution time'])\n",
    "time_data.loc[len(time_data)] = [1,'weight init',0.14792394638061523]\n",
    "time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def forward_prop(img,time_data,hparameters = {\"stride\" : 2, \"f\": 2}):\n",
    "    no_img = img.shape[0]\n",
    "    #conv block 1 <down>\n",
    "    start = time.time()\n",
    "    Z_1, cache_conv11 = conv_forward(img, W_11, b_11, strides=(1,1),filter_size=(3,3))\n",
    "    Z_1, cache_conv12 = conv_forward(Z_1, W_12, b_12, strides=(1,1),filter_size=(3,3))\n",
    "    A_1, cache_1 = pool_forward(Z_1, hparameters)\n",
    "    b1 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV1',b1-start]\n",
    "    print('====== 1 =====')\n",
    "    #conv block 2 <down>\n",
    "    Z_2, cache_conv21 = conv_forward(A_1, W_21, b_21, strides=(1,1),filter_size=(3,3))\n",
    "    Z_2, cache_conv22 = conv_forward(Z_2, W_22, b_22, strides=(1,1),filter_size=(3,3))\n",
    "    A_2, cache_2 = pool_forward(Z_2, hparameters)\n",
    "    b2 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV2',b2-b1]\n",
    "    print('====== 2 =====')\n",
    "    #conv block 3 <down>\n",
    "    Z_3, cache_conv31 = conv_forward(A_2, W_31, b_31, strides=(1,1),filter_size=(3,3))\n",
    "    Z_3, cache_conv32 = conv_forward(Z_3, W_32, b_32, strides=(1,1),filter_size=(3,3))\n",
    "    A_3, cache_3 = pool_forward(Z_3, hparameters)\n",
    "    b3 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV3',b3-b2]\n",
    "    print('====== 3 =====')\n",
    "    #conv block 4 <down>\n",
    "    Z_4, cache_conv41 = conv_forward(A_3, W_41, b_41, strides=(1,1),filter_size=(3,3))\n",
    "    Z_4, cache_conv42 = conv_forward(Z_4, W_42, b_42, strides=(1,1),filter_size=(3,3))\n",
    "    A_4, cache_4 = pool_forward(Z_4, hparameters)\n",
    "    b4 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV4',b4-b3]\n",
    "    print('====== 4 =====')\n",
    "    #conv block 5 (center)\n",
    "    Z_5, cache_conv51 = conv_forward(A_4, W_51, b_51, strides=(1,1),filter_size=(3,3))\n",
    "    Z_5, cache_conv52 = conv_forward(Z_5, W_52, b_52, strides=(1,1),filter_size=(3,3))\n",
    "    b5 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV5',b5-b4]\n",
    "    print('====== 5 =====')\n",
    "    #conv block 6 <up>\n",
    "    Z_6T = Conv2DTranspose_layer(Z_5, W_61, padding=\"same\", strides=(2,2))\n",
    "    Z_61 = concat(Z_6T,Z_4)\n",
    "    Z_6, cache_conv62 = conv_forward(Z_61, W_62, b_62, strides=(1,1),filter_size=(3,3))\n",
    "    Z_6, cache_conv63 = conv_forward(Z_6, W_63, b_63, strides=(1,1),filter_size=(3,3))\n",
    "    b6 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV6',b6-b5]\n",
    "    print('====== 6 =====')\n",
    "    #conv block 7 <up>\n",
    "    Z_7T = Conv2DTranspose_layer(Z_6, W_71, padding=\"same\", strides=(2,2))\n",
    "    Z_71 = concat(Z_7T,Z_3)\n",
    "    Z_7, cache_conv72 = conv_forward(Z_71, W_72, b_72, strides=(1,1),filter_size=(3,3))\n",
    "    Z_7, cache_conv73 = conv_forward(Z_7, W_73, b_73, strides=(1,1),filter_size=(3,3))\n",
    "    b7 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV7',b7-b6]\n",
    "    print('====== 7 =====')\n",
    "    #conv block 8 <up>\n",
    "    Z_8T = Conv2DTranspose_layer(Z_7, W_81, padding=\"same\", strides=(2,2))\n",
    "    Z_81 = concat(Z_8T,Z_2)\n",
    "    Z_8, cache_conv82 = conv_forward(Z_81, W_82, b_82, strides=(1,1),filter_size=(3,3))\n",
    "    Z_8, cache_conv83 = conv_forward(Z_8, W_83, b_83, strides=(1,1),filter_size=(3,3))\n",
    "    b8 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV8',b8-b7]\n",
    "    print('====== 8 =====')\n",
    "    #conv block 9 <up>\n",
    "    Z_9T = Conv2DTranspose_layer(Z_8, W_91, padding=\"same\", strides=(2,2))\n",
    "    Z_91 = concat(Z_9T,Z_1)\n",
    "    Z_9, cache_conv92 = conv_forward(Z_91, W_92, b_92, strides=(1,1),filter_size=(3,3))\n",
    "    Z_9, cache_conv93 = conv_forward(Z_9, W_93, b_93, strides=(1,1),filter_size=(3,3))\n",
    "    b9 = time.time()\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV9',b9-b8]\n",
    "    print('====== 9 =====')\n",
    "    #conv block 10 <output>\n",
    "    Z_out, cache_conv_out = conv_forward(Z_9, W_out, b_out, strides=(1,1),filter_size=(1,1))\n",
    "    b10 = time.time()\n",
    "    print('====== 10 =====')\n",
    "    time_data.loc[len(time_data)] = [no_img,'CONV10',b10-b9]\n",
    "    total_time = b10-start\n",
    "    time_data.loc[len(time_data)] = [no_img,'Total',total_time]\n",
    "    return Z_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 1 =====\n",
      "====== 2 =====\n",
      "====== 3 =====\n",
      "====== 4 =====\n",
      "====== 5 =====\n",
      "====== 6 =====\n"
     ]
    }
   ],
   "source": [
    "output = forward_prop(img,time_data,hparameters = {\"stride\" : 2, \"f\": 2})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "forward prop exp 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
